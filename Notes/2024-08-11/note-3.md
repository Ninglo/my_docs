个人的理解：
玄学本身其实很类似一个机器学习的模型。它不太追求可解释性，而把重点放在，基于过去的统计数据对未来进行预测。
但这个系统最大的问题是其 reward 函数设计得很糟糕。“个人觉着准不准” 这个判断实在太不精确了，并不是一个很 solid 的结论。

人会有很大的认知偏差：多数人会下意识接受夸赞的话语，无论自己到底是不是这样。所以如果一个结论给出的正向反馈太多，那这个人说准其实并不是那么致信。

另外一点，人本身是复杂的，很多特质其实正着说、反着说都成立，只是不同人处于同一条从零到一光谱中的不同位置。
因为白熊效应的影响，当我们听到有人说：“你有某某特质的时候”，我们往往下意识想到的是对这些论点的证明论据。
拿我自己举个例子，我回顾了一下评论的内容，也自我代入了一下。我发现在讲这个人执行力很强的时候，我觉着似乎对我很成立 ，但在另一条评论下说，这个人很懒的时候好像对我 也是这样 因为我确实能找到自己很懒的例子也能找到自己勤快的例子 可在每个具体的语境下，我都想象的是那些证明的例子