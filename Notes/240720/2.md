在日常使用 VSCode 开发项目的过程中，我经常会因当前某些场景的启发或突然的灵光一闪而产出一些有趣的 Idea。但为了避免上下文切换的带来的开销，我并不能立刻全身心的投入精力到这些新想出来的 Idea 之中。在这个阶段，我要做的是尽可能快的把这些想法记录下来，以避免灵感的遗忘。

但又有一个严峻的问题，在使用电脑时，我做的往往都是非常需要聚焦的任务。为保证注意力集中，我会把手机放到一些我很难立刻顺手够到的地方。可是，我当前记录想法的工作流又非常依赖语音转文字功能：在不严格追求输出结果准确性的前提下，语音转文字要比手写或者键盘输入的效率高太多了。可是，直接在电脑上使用语音输入的体验远远不如手机端，这迫使我在需要语音转文字能力的时候，还是得把手机拿出来。
Mac 的语音输入功能主要有以下几个问题：首先，它同时只能支持一种语言。在我说一些中英夹杂内容的时候，它总是会错误的识别我想输入的内容，把英文内容输出为一些牛头不对马嘴的中文。而当我输入纯英文语音时，情况就变得更糟，它真的一点英文都不会输出，以至于我完全没法用语音进行记录该场景下一些想法。另外很抽象的一点是，不知道是不是因为训练数据导致的过拟合，Mac 内置的语音转文字经常在生成文本开头插入 ”嘿Siri“ 几个字。综上几点让我只有在迫不得已的时候，才会使用 Mac 原生的语音输入法。

然而，我又并不想使用三方输入法。这里的原因以下几点：
一是因为隐私，三方输入法会把我的数据上传到云端，它们并没有 Mac 自带的输入法隐私性好。
同时，它们的语音转文字模型大多还部署在云上，需要联网才能使用。这是我不能接受的（我不能保证所有需要语音输入的场景下，身边都有网络）。
再者，安装三方输入法意味着，我的工作流对应用的依赖关系会更复杂，迁移电脑或临时使用其他人电脑时都多有不便。再退一步说，出于对简洁美的追求，我也不想为了这样一个功能，就为自己的工作流中带来切换输入法这样如此大复杂度的变更。

但在对 Copilot 进行深度使用后，我发现它的语音识别能力做的非常优雅：
首先，Copilot 的语音识别能力是一个通用的底层能力，其并不与 Copilot 插件绑定，而是由独立插件来承载，其他插件也可以调用相关能力。
其次，该能力对语音识别准确度非常之高：吐字清晰、语速正常的前提下，基本没有语音识别出错的情况（再怎么说我也是普通话一乙，这点要求还是能达到的）。
最关键的是，它支持单段语音中的多语言识别，我可以同时输入多种语言而不担心它识别错误。
最后，由于它本身是 VSCode 的一项基础能力，我就可以很轻松的在 VSCode 中调用其能力，进而完成初始的需求：**即在灵感出现的时刻，快速的完成笔记创建并记录的流程**。

如果有一种方案可以在 VSCode 内实现上述需求，那它显然就是最为理想的解决方案。
因而，我开始调研是否有现成插件实现此项能力。但可惜的是，因为 VSCode 的语音识别能力是与 Copilot 一同推出的，其发布时间尚短。所以很可惜，虽然有一系列的插件实现了快速笔记记录的能力，但它们都并不能直接触发语音转文字功能。虽然这无非就是多一两个快捷键操作的事情，但因为这个行为毫无意义，真的做起来也非常让人不爽。灵感转瞬即逝，我们必须尽可能快的记录它，中间的操作流程显然越少越好，更何况这一步完全是理论上可避免的多余操作。

因此，我开发了 [Quick Voice Note](https://marketplace.visualstudio.com/items?itemName=ninglo.quick-voice-note) 插件， 用一个快捷键完成创建新笔记文件并触发 VSCode 语音输入模式的功能。在使用 VSCode 的过程中，一旦有了新的想法，我们就可以快速的触发这项功能，然后开始我们笔记的记录。当记录完成之后，我们又可以直接关闭打开的页面，而回过头继续完成手头的工作。文件的笔记的内容则会保留至设置的路径下，这完美解决了我的需求。
欢迎大家体验并提供反馈，谢谢！

> 项目地址：https://github.com/Ninglo/quick-voice-note
> 下载链接：https://marketplace.visualstudio.com/items?itemName=ninglo.quick-voice-note

[[tag/VSCode]] [[tag/Extension]] [[tag/Note]] [[tag/Voice Input]] [[tag/Software]]
