ai 也会偷懒 只是你还没有发现
不管了 美美躺平的封面


无论你给AI了一个清晰完善的需求描述，还是简简单单一两句话 似乎AI都能给你一个又大又全，内容详实的回复，这就给人了一种错觉，好像AI就是如此的勤勤勉勉，无论你怎么样对待他，他就持续如故的认真回答你的问题

但如果你认真去分析每次回答 你就可以发现，其实这些这二两种回答唯一相像的可能只有其中的结构和回答数量，具体的质量完全不同。可能。只是这种结构和数量看着很有冲击力所以给人了一种呃他好像每一次回答呃水平都类似的错。


想要比喻的话，AI现在的AI就有点像是一个挺聪明但是学生思维很重的实习生。他能够相对比较良好的完成你交代的任务，而且做事也似乎勤勤勉勉，但他不会去更深入的思考这个问题的本身。其实第一性原理就明确的告诉我们了，我们首先要做的是确定需求本身的成立与否，再去优化，无论你优化一个东西多么的多么的好，如果它本身的逻辑不成立，那你这些优化也是白搭。而AI现在的状态就很像是这种犯了这个错的一个小朋友，当用户给他提出了一些可能不那么合理的问题，他还是老老实实的继续做下去。而这种做下去反过来又给因为很轻松，又给了使用者一些错觉，就是这个东西，好像真的能做成，然后在这种错误的道路上越走越远，直到可能最终接近交付，才发现呃这个描述需求故事本身不甚成立呃最后涂涂浪费精力。


但很有意思的一点是，AI本身其实并非是不了解这些思想，就是说如果你给他一些很简单适当的提示，告诉他我们需要一些follow up, 先把需求想明确，再开始具体的任务工作以后，他还是能给你一些比较高质量的回答以及引导的问题。就像一个相对比较有职场经验的资深老油条，与他一同探讨，我们能获取一个可能有建设性的意意见，然后并找出那个可能真正重要的问题和思路。就像我上面说的，现在的AI大多都被驯化的太好，他们自己不敢使用这样的能力。一定需要你手动的给他一些prompt的提示，他才能嗯将注意力分散到这些呃可能更深入层次的问题上。

所以至少在目前的阶段，我们应该更有意识的去判定这两种不同的使用AI的模式，或者思考的模式，可能对于一些比较简单，我们也能想明确的问题。我们就需要让他直接干活。那其实就很简单的直接描述需求，让他给我一些答复就直接可用了。但是在更多的场景下，尤其是在我们那种想法初创的时期，可能一定适当的prompt引导，让他去给我们一些更深刻的意见，而非是过早的开始关注号的问题是一个。更呃合理选择。

而具体到使用方式，其实有一种非常有趣的思路，就是我们可以找到那些关于职场经验的教程以及一些核心的观点，把这些prompt将它植入进去，植入我的prompt，做一些提示以后，他就能获得这些治疗。也就是说，他是AI本身一点就透，不需要很多前置的教学。有这样的提示以后，他们就能给我们一些相应聪明的想法。当然了，同时这个过程中我们自己也不能放弃思考，也需要不断的一个更全局类似manager的视角，给他一定的引导或者说探探索，才能找出最大的最好的这个实践方式。

我觉得可能在展开认知科学这个视角会比较有意思，当然我不是这方面的专家，我就先就一些抽象的描述来，或者说一些我日常的体验来给出一些想法
其实，不只是AI会偷懒，人类自己的偷懒现象会更加严重。可能稍微有一点挫折或者是其他因素引导，就会让人放弃动脑的思考。因为动脑本身是一个非常消耗精力能量的事情，人们下意识的会回避他。那尤其是在像我们有了一个AI这样的助手之后，好像很多的问题都直接问他解答了。但这其实把我们的思考排除在外，我们可能更像是一个需求的传声筒，别人给我们交付，或者我们自己想到的任务，不假思索的直接喂给AI，希望他能给一个确定的答复。这样的流程，我觉得这是非常有问题的，因为现在的AI还有一个巨大的问题在于他没有记忆，也没有太多的你自己的上下文。换句话说，这个需求的合理性本身可能未必是一个普世放四海而皆准的答案，它更多取决于你具体的场景需要，也就是说，更多为这个答案决判断是否有价值的是人自己。但如果你放弃了这种思考或者说减轻思考，那整体的思路和判断都沿着AI的流程来，那很可能他不会能套用到我们自己的具体需求场景。最后变成一个有用的工具。所以我我们人要把持着这些所谓尺度或者说衡量、定标准、定义这样的角色，一定要让AI清晰的知道什么是好，什么是坏，然后由我们来判断。在此之后，把它当做一个助手，继续改进我们的功能需求


笑死，确实是这样的。补充下我另外的一个感受是：AI本身是能理解这些职场工作思路的，很多时候它不需要解释过多，只需要给一个提示就能一点就透。比起教那些真实的实习生而言都要省心很多。
感觉更多时候，只是AI自己的“注意力”没有放到这里。就像我上文说的，它似乎被驯化的一定要解决用户的问题，而不是先想着去质疑本身的合理性。
相当于，现在AI还是一个面向很精英用户人群的应用。对于大多数普通人而言，可能他自己都没有在工作生活中践行这种清晰结构化描述需求的方式，又何谈在与AI的对话中做到这样的表达呢？
我觉得AI 在很多时候，结合正确 prompt 的情况下，已经能起到一个类似导师身份的效果：通过它一些不断的follow up 问题引导，让人有一个更清晰明确的思路。
但矛盾的是，这种引导的prompt其实还是要那些使用AI的专家，而非普通人才能做出来。我个人以为，AI 的伟大之处不止在于它现在的智能程度很高；同样重要的是它可以普遍的应用到每一个人身上，是每一个人忠实的伙伴。如果能让更多普通人也开始可以更深入的发掘AI的潜能，我想一定会是一件很有市场和价值的事情

确实是这样，我感觉现在的AI有点被驯化的太好了。有点儿像公司里聪明但学生思维很重的实习生。不敢去 challenge 老板。老板说的需求有问题，我也是先做，至于效果如何，它其实不怎么关注。
对那种比较专业使用AI的人来说，这个问题并不严重：他能意识到这种敷衍是因为自己描述不清晰导致的。
但是，对刚使用AI 尝鲜的新用户来说，这个问题就比较严重了。用户最开始体验应用 ai 的思路，可能就是像正常聊天一样，随口一句话一句话蹦自己的思路。
如果如果他发现AI第一次回复的效果又大又空，而他又没能意识到AI这样做的原因是因为自己的需求不清晰。可能就会怀疑AI本身的智能程度，然后彻底放弃后续的使用。
相当于用户在应用本身漏斗的第一层就流失掉了。
显然我们也很难假设每个用户在第一次使用AI时，就已经很精通AI。而我觉得绝大多数人也不会在第一次使用 ai 的时候就很严肃的，像写需求文档一样，花大几百个字描述好自己的需求，更多就是随口一问看看效果。
如果AI没有一些像follow up的提问给他引导，告诉用户你这种随口提问的使用方式是错误的话。那用户可能就完全忽视了ai 其实拥有的巨大潜力，给他一种完全错误的认识，让用户后续使用意愿大幅下降。
我觉得这也算是一种很可惜的现象。
